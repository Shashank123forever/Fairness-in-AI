{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e325e64",
   "metadata": {},
   "source": [
    "# Example Usage of Dbias Package on a test data\n",
    "\n",
    "Author: Deepak John Reji\n",
    "\n",
    "This Package is part of the Research topic \"Bias and Fairness in AI\" conducted by Deepak John Reji, Shaina Raza. If you use this work (code, model or dataset),\n",
    "\n",
    "Please star at: Bias & Fairness in AI, (2022), GitHub repository, https://github.com/dreji18/Fairness-in-AI\n",
    "\n",
    "PyPI Repo : https://pypi.org/project/Dbias/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c32d54",
   "metadata": {},
   "source": [
    "#### Installing the Packages and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b3c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Dbias in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: numpy==1.19.5 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from Dbias) (1.19.5)\n",
      "Requirement already satisfied: pandas==1.2.4 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from Dbias) (1.2.4)\n",
      "Requirement already satisfied: tensorflow==2.4.1 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from Dbias) (2.4.1)\n",
      "Requirement already satisfied: transformers==4.6.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from Dbias) (4.6.1)\n",
      "Requirement already satisfied: spacy==3.2.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from Dbias) (3.2.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from pandas==1.2.4->Dbias) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from pandas==1.2.4->Dbias) (2.8.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (2.11.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy==3.2.1->Dbias) (0.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy==3.2.1->Dbias) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (20.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (4.56.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (3.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (1.0.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy==3.2.1->Dbias) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (1.7.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (52.0.0.post20210125)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (3.7.4.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy==3.2.1->Dbias) (8.0.13)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy==3.2.1->Dbias) (2.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy==3.2.1->Dbias) (1.0.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (1.12.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (3.3.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.4.1->Dbias) (2.10.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (0.36.2)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (2.7.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (0.13.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.4.1->Dbias) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.4.1->Dbias) (0.3.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.4.1->Dbias) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (3.17.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1->Dbias) (1.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers==4.6.1->Dbias) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers==4.6.1->Dbias) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers==4.6.1->Dbias) (0.0.45)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers==4.6.1->Dbias) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers==4.6.1->Dbias) (0.0.8)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers==4.6.1->Dbias) (0.10.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.1->Dbias) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy==3.2.1->Dbias) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy==3.2.1->Dbias) (5.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1->Dbias) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1->Dbias) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1->Dbias) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1->Dbias) (2.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1->Dbias) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1->Dbias) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1->Dbias) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1->Dbias) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1->Dbias) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1->Dbias) (1.32.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.1->Dbias) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from jinja2->spacy==3.2.1->Dbias) (2.0.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from sacremoses->transformers==4.6.1->Dbias) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->Dbias) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->Dbias) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->Dbias) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->Dbias) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->Dbias) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->Dbias) (3.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-pipeline==any\n",
      "  Using cached https://huggingface.co/d4data/en_pipeline/resolve/main/en_pipeline-any-py3-none-any.whl (436.3 MB)\n",
      "Requirement already satisfied: spacy-transformers<1.2.0,>=1.1.3 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from en-pipeline==any) (1.1.3)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from en-pipeline==any) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (8.0.13)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (1.19.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (2.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (4.56.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (0.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (3.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (0.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (52.0.0.post20210125)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (3.7.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (0.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (2.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (3.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (0.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (20.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (2.25.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (1.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-pipeline==any) (2.0.6)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\deepak.reji\\appdata\\roaming\\python\\python37\\site-packages (from spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (1.8.1)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (0.8.3)\n",
      "Requirement already satisfied: transformers<4.13.0,>=3.4.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (4.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-pipeline==any) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-pipeline==any) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-pipeline==any) (5.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-pipeline==any) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-pipeline==any) (2.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-pipeline==any) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-pipeline==any) (2021.10.8)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers<4.13.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (0.0.8)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers<4.13.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (0.0.45)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers<4.13.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (2021.4.4)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers<4.13.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (0.10.3)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers<4.13.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (2.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from transformers<4.13.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (3.4.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-pipeline==any) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-pipeline==any) (2.0.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from sacremoses->transformers<4.13.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\deepak.reji\\anaconda3\\lib\\site-packages (from sacremoses->transformers<4.13.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.3->en-pipeline==any) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Dbias\n",
    "!pip install https://huggingface.co/d4data/en_pipeline/resolve/main/en_pipeline-any-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b613eaa0",
   "metadata": {},
   "source": [
    "#### Loading the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7570b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dbias.text_debiasing import *;\n",
    "from Dbias.bias_classification import *;\n",
    "from Dbias.bias_recognition import *;\n",
    "from Dbias.bias_masking import *;\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e3667",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72dd5aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Swiss voters will head to the polls to decide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unbelievably, with all they had seen their chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And while states like Massachusetts�among othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oxford chose \"climate emergency\" as the word o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This, of course, was before the president igno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Swiss voters will head to the polls to decide ...\n",
       "1  Unbelievably, with all they had seen their chi...\n",
       "2  And while states like Massachusetts�among othe...\n",
       "3  Oxford chose \"climate emergency\" as the word o...\n",
       "4  This, of course, was before the president igno..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sample data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eabf814",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7aa045a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_classification(x):\n",
    "    classi_out = classify(x)\n",
    "    return classi_out[0]['label'], classi_out[0]['score']\n",
    "\n",
    "def custom_recognizer(x):\n",
    "    biased_words = recognizer(x)\n",
    "    biased_words_list = []\n",
    "    for id in range(0, len(biased_words)):\n",
    "        biased_words_list.append(biased_words[id]['entity'])\n",
    "    return \", \".join(biased_words_list)\n",
    "\n",
    "def custom_debiasing(x):\n",
    "    suggestions = run(x)\n",
    "    if suggestions == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "      all_suggestions = []\n",
    "      for sent in suggestions[0:3]:\n",
    "        all_suggestions.append(sent['Sentence'])\n",
    "      return \"\\n\\n\".join(all_suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cdf5e5",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0442a3c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Swiss voters will head to the polls to decide ...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.918929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unbelievably, with all they had seen their chi...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And while states like Massachusetts�among othe...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.894321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oxford chose \"climate emergency\" as the word o...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.960910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This, of course, was before the president igno...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Pelosi�s coronavirus plan uses the pandemic to...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.822288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Trump has publicly taken aim at Germany � even...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.940148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Democrats and Republicans stood and applauded ...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.911157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Haqqani claimed the Taliban are just looking f...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Using the International Holocaust Remembrance ...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.842141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       state  \\\n",
       "0    Swiss voters will head to the polls to decide ...  Non-biased   \n",
       "1    Unbelievably, with all they had seen their chi...      Biased   \n",
       "2    And while states like Massachusetts�among othe...      Biased   \n",
       "3    Oxford chose \"climate emergency\" as the word o...  Non-biased   \n",
       "4    This, of course, was before the president igno...      Biased   \n",
       "..                                                 ...         ...   \n",
       "173  Pelosi�s coronavirus plan uses the pandemic to...      Biased   \n",
       "174  Trump has publicly taken aim at Germany � even...      Biased   \n",
       "175  Democrats and Republicans stood and applauded ...      Biased   \n",
       "176  Haqqani claimed the Taliban are just looking f...      Biased   \n",
       "177  Using the International Holocaust Remembrance ...  Non-biased   \n",
       "\n",
       "     probability  \n",
       "0       0.918929  \n",
       "1       0.995291  \n",
       "2       0.894321  \n",
       "3       0.960910  \n",
       "4       0.995373  \n",
       "..           ...  \n",
       "173     0.822288  \n",
       "174     0.940148  \n",
       "175     0.911157  \n",
       "176     0.995164  \n",
       "177     0.842141  \n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running Dbias classfication to classify whether a news article is biased or not\n",
    "df[['state', 'probability']] = df['text'].apply(lambda x: custom_classification(x)).to_list()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a37c407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "      <th>probability</th>\n",
       "      <th>biased words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Swiss voters will head to the polls to decide ...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.918929</td>\n",
       "      <td>homophobia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unbelievably, with all they had seen their chi...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995291</td>\n",
       "      <td>Unbelievably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And while states like Massachusetts�among othe...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.894321</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oxford chose \"climate emergency\" as the word o...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.960910</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This, of course, was before the president igno...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995373</td>\n",
       "      <td>ignored, brutal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       state  probability  \\\n",
       "0  Swiss voters will head to the polls to decide ...  Non-biased     0.918929   \n",
       "1  Unbelievably, with all they had seen their chi...      Biased     0.995291   \n",
       "2  And while states like Massachusetts�among othe...      Biased     0.894321   \n",
       "3  Oxford chose \"climate emergency\" as the word o...  Non-biased     0.960910   \n",
       "4  This, of course, was before the president igno...      Biased     0.995373   \n",
       "\n",
       "      biased words  \n",
       "0       homophobia  \n",
       "1     Unbelievably  \n",
       "2                   \n",
       "3                   \n",
       "4  ignored, brutal  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running Dbias recognition to recognize biased words/phrases\n",
    "df['biased words'] = df['text'].apply(lambda x: custom_recognizer(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc365299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "Hurray! We were able to successfully de-bias the sentence fragment\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "The Sentence is Non biased\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is biased but the model failed to pick up portion of bias\n",
      "We were able to reduce the amount of bias!\n",
      "We were able to reduce the amount of bias!\n",
      "The Sentence is Non biased\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "      <th>probability</th>\n",
       "      <th>biased words</th>\n",
       "      <th>suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Swiss voters will head to the polls to decide ...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.918929</td>\n",
       "      <td>homophobia</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unbelievably, with all they had seen their chi...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995291</td>\n",
       "      <td>Unbelievably</td>\n",
       "      <td>yet, with all they had seen their child suffer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And while states like Massachusetts�among othe...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.894321</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oxford chose \"climate emergency\" as the word o...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.960910</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This, of course, was before the president igno...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995373</td>\n",
       "      <td>ignored, brutal</td>\n",
       "      <td>This, of course, was before the president disb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Pelosi�s coronavirus plan uses the pandemic to...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.822288</td>\n",
       "      <td>cram, loopholes</td>\n",
       "      <td>Pelosi�s coronavirus plan uses the pandemic to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Trump has publicly taken aim at Germany � even...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.940148</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Democrats and Republicans stood and applauded ...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.911157</td>\n",
       "      <td>saluted</td>\n",
       "      <td>Democrats and Republicans stood and applauded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Haqqani claimed the Taliban are just looking f...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995164</td>\n",
       "      <td>laughably, murderous</td>\n",
       "      <td>Haqqani claimed the Taliban are just looking f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Using the International Holocaust Remembrance ...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.842141</td>\n",
       "      <td>delegitimize</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       state  \\\n",
       "0    Swiss voters will head to the polls to decide ...  Non-biased   \n",
       "1    Unbelievably, with all they had seen their chi...      Biased   \n",
       "2    And while states like Massachusetts�among othe...      Biased   \n",
       "3    Oxford chose \"climate emergency\" as the word o...  Non-biased   \n",
       "4    This, of course, was before the president igno...      Biased   \n",
       "..                                                 ...         ...   \n",
       "173  Pelosi�s coronavirus plan uses the pandemic to...      Biased   \n",
       "174  Trump has publicly taken aim at Germany � even...      Biased   \n",
       "175  Democrats and Republicans stood and applauded ...      Biased   \n",
       "176  Haqqani claimed the Taliban are just looking f...      Biased   \n",
       "177  Using the International Holocaust Remembrance ...  Non-biased   \n",
       "\n",
       "     probability          biased words  \\\n",
       "0       0.918929            homophobia   \n",
       "1       0.995291          Unbelievably   \n",
       "2       0.894321                         \n",
       "3       0.960910                         \n",
       "4       0.995373       ignored, brutal   \n",
       "..           ...                   ...   \n",
       "173     0.822288       cram, loopholes   \n",
       "174     0.940148                         \n",
       "175     0.911157               saluted   \n",
       "176     0.995164  laughably, murderous   \n",
       "177     0.842141          delegitimize   \n",
       "\n",
       "                                            suggestion  \n",
       "0                                                       \n",
       "1    yet, with all they had seen their child suffer...  \n",
       "2                                                       \n",
       "3                                                       \n",
       "4    This, of course, was before the president disb...  \n",
       "..                                                 ...  \n",
       "173  Pelosi�s coronavirus plan uses the pandemic to...  \n",
       "174                                                     \n",
       "175  Democrats and Republicans stood and applauded ...  \n",
       "176  Haqqani claimed the Taliban are just looking f...  \n",
       "177                                                     \n",
       "\n",
       "[178 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running Dbias to recommend unbiased/reduced bias news fragment\n",
    "df['suggestion'] = df['text'].apply(lambda x: custom_debiasing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53ac58ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "      <th>probability</th>\n",
       "      <th>biased words</th>\n",
       "      <th>suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Swiss voters will head to the polls to decide ...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.918929</td>\n",
       "      <td>homophobia</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unbelievably, with all they had seen their chi...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995291</td>\n",
       "      <td>Unbelievably</td>\n",
       "      <td>yet, with all they had seen their child suffer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And while states like Massachusetts�among othe...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.894321</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oxford chose \"climate emergency\" as the word o...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.960910</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This, of course, was before the president igno...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995373</td>\n",
       "      <td>ignored, brutal</td>\n",
       "      <td>This, of course, was before the president disb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Pelosi�s coronavirus plan uses the pandemic to...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.822288</td>\n",
       "      <td>cram, loopholes</td>\n",
       "      <td>Pelosi�s coronavirus plan uses the pandemic to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Trump has publicly taken aim at Germany � even...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.940148</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Democrats and Republicans stood and applauded ...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.911157</td>\n",
       "      <td>saluted</td>\n",
       "      <td>Democrats and Republicans stood and applauded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Haqqani claimed the Taliban are just looking f...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.995164</td>\n",
       "      <td>laughably, murderous</td>\n",
       "      <td>Haqqani claimed the Taliban are just looking f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Using the International Holocaust Remembrance ...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.842141</td>\n",
       "      <td>delegitimize</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       state  \\\n",
       "0    Swiss voters will head to the polls to decide ...  Non-biased   \n",
       "1    Unbelievably, with all they had seen their chi...      Biased   \n",
       "2    And while states like Massachusetts�among othe...      Biased   \n",
       "3    Oxford chose \"climate emergency\" as the word o...  Non-biased   \n",
       "4    This, of course, was before the president igno...      Biased   \n",
       "..                                                 ...         ...   \n",
       "173  Pelosi�s coronavirus plan uses the pandemic to...      Biased   \n",
       "174  Trump has publicly taken aim at Germany � even...      Biased   \n",
       "175  Democrats and Republicans stood and applauded ...      Biased   \n",
       "176  Haqqani claimed the Taliban are just looking f...      Biased   \n",
       "177  Using the International Holocaust Remembrance ...  Non-biased   \n",
       "\n",
       "     probability          biased words  \\\n",
       "0       0.918929            homophobia   \n",
       "1       0.995291          Unbelievably   \n",
       "2       0.894321                         \n",
       "3       0.960910                         \n",
       "4       0.995373       ignored, brutal   \n",
       "..           ...                   ...   \n",
       "173     0.822288       cram, loopholes   \n",
       "174     0.940148                         \n",
       "175     0.911157               saluted   \n",
       "176     0.995164  laughably, murderous   \n",
       "177     0.842141          delegitimize   \n",
       "\n",
       "                                            suggestion  \n",
       "0                                                       \n",
       "1    yet, with all they had seen their child suffer...  \n",
       "2                                                       \n",
       "3                                                       \n",
       "4    This, of course, was before the president disb...  \n",
       "..                                                 ...  \n",
       "173  Pelosi�s coronavirus plan uses the pandemic to...  \n",
       "174                                                     \n",
       "175  Democrats and Republicans stood and applauded ...  \n",
       "176  Haqqani claimed the Taliban are just looking f...  \n",
       "177                                                     \n",
       "\n",
       "[178 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef3b7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"suggestions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b537d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
